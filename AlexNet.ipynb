{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvp3FHHnZhze1vkG2nvzjf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhsanTariqGill/Image-Forgery-Type-Detection/blob/main/AlexNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebYns3bmkOOx",
        "outputId": "026dd653-236b-451c-8e33-6b0b00cc0d6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n"
      ],
      "metadata": {
        "id": "ZdNiBc6EkVHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained AlexNet model\n",
        "alexnet = models.alexnet(pretrained=True)\n",
        "\n",
        "# Modify the model to use it as a feature extractor\n",
        "alexnet.classifier = torch.nn.Sequential(*list(alexnet.classifier.children())[:-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQL26hSoqsXM",
        "outputId": "5c7bb831-bd16-4973-c019-7433ba07993c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:02<00:00, 89.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations for your dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n"
      ],
      "metadata": {
        "id": "kXinHFSOqy-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'your_dataset_directory' with the path to your dataset\n",
        "dataset = ImageFolder(root='/content/drive/MyDrive/Datasets/Type_Det_Enhanced', transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "0AVhYzGQz9oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store features and labels\n",
        "all_features = []\n",
        "all_labels = []\n",
        "\n",
        "# Initialize a counter for the number of images processed\n",
        "num_images_processed = 0\n",
        "\n",
        "# Feature extraction\n",
        "for inputs, labels in dataloader:\n",
        "    # Get features from AlexNet\n",
        "    features = alexnet(inputs)\n",
        "\n",
        "    # Move features to CPU and convert to NumPy array, then store\n",
        "    all_features.extend(features.detach().cpu().numpy())\n",
        "\n",
        "    # Store labels\n",
        "    all_labels.extend(labels.numpy())\n",
        "\n",
        "    # Update the number of images processed\n",
        "    num_images_processed += inputs.size(0)\n",
        "\n",
        "# After the loop, print out the total number of images processed\n",
        "print(f\"Total number of images processed: {num_images_processed}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzOH9Z7u0gOw",
        "outputId": "8e591683-f65d-4014-fb19-c662cac17cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images processed: 1512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kWPSISLM7FG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_features_tensor = torch.tensor(all_features)\n",
        "all_labels_tensor = torch.tensor(all_labels)\n",
        "\n",
        "# Define the save paths\n",
        "features_save_path = '/content/drive/MyDrive/AlexNet_Type_Exps/Exp02/feature_labels/all_features.pt'\n",
        "labels_save_path = '/content/drive/MyDrive/AlexNet_Type_Exps/Exp02/feature_labels/all_labels.pt'\n",
        "\n",
        "# Save the tensors to your drive\n",
        "torch.save(all_features_tensor, features_save_path)\n",
        "torch.save(all_labels_tensor, labels_save_path)\n"
      ],
      "metadata": {
        "id": "es5oJRhz383x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8e80c87-c9c7-4709-8c4d-1368c104393d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-c9ec0f2024d2>:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  all_features_tensor = torch.tensor(all_features)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.class_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkmbSh3w0kNg",
        "outputId": "27d599bc-4d39-42c5-9dbc-783904b6e9a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'copy_moved': 0, 'not_forged': 1, 'splicied': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the features and labels\n",
        "all_features = torch.load('/content/drive/MyDrive/AlexNet_Type_Exps/Exp02/feature_labels/all_features.pt')\n",
        "all_labels = torch.load('/content/drive/MyDrive/AlexNet_Type_Exps/Exp02/feature_labels/all_labels.pt')\n"
      ],
      "metadata": {
        "id": "CyXzcWnW2a4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SVM Classifier"
      ],
      "metadata": {
        "id": "Jw0nGtyq5lRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "import numpy as np\n",
        "X = np.array(all_features)\n",
        "y = np.array(all_labels)\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the SVM classifier\n",
        "svm_classifier = SVC(kernel='linear')  # You can experiment with different kernels\n",
        "\n",
        "# Train the SVM classifier\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "w6H-aF__5eG3",
        "outputId": "63712cf3-53aa-4e8e-ec0e-51f540551c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict using the trained classifier\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzZawjAf518Y",
        "outputId": "15fd870e-2d5a-46ae-ad93-e7841d88ca37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6732673267326733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate the classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the classification report\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bg7bGwVD56Pi",
        "outputId": "ccda9c4b-33a3-4b36-afa4-9f7ceef2f1f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.61      0.60        97\n",
            "           1       0.84      0.78      0.81       107\n",
            "           2       0.60      0.63      0.61        99\n",
            "\n",
            "    accuracy                           0.67       303\n",
            "   macro avg       0.67      0.67      0.67       303\n",
            "weighted avg       0.68      0.67      0.68       303\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Adding Classfication layer in Alexnet"
      ],
      "metadata": {
        "id": "F7-npym19z-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "SrVJ_p_p6OXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained AlexNet model\n",
        "alexnet = models.alexnet(pretrained=True)\n",
        "\n",
        "# Modify the model to use it as a feature extractor\n",
        "alexnet.classifier = nn.Sequential(*list(alexnet.classifier.children())[:-1])"
      ],
      "metadata": {
        "id": "D6G8-dcm-hku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e855516a-b60e-4964-a1f3-70b6daffac86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define custom classifier\n",
        "class CustomClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(4096, 1024)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(1024, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "jn7nA5FR-mZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attach custom classifier to AlexNet\n",
        "classifier = CustomClassifier()\n",
        "alexnet.classifier.add_module('custom_classifier', classifier)"
      ],
      "metadata": {
        "id": "AHNnCmYo-q2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations for dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n"
      ],
      "metadata": {
        "id": "0aDaM4Kh-t20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "dataset = ImageFolder(root='/content/drive/MyDrive/Colab Notebooks/Type_classification_dataset', transform=transform)\n",
        "\n",
        "# Split dataset into train and test set\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
      ],
      "metadata": {
        "id": "c0MW8vjY-wWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "QZuzyGQo-zJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(alexnet.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "veMCxaGk_EWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    alexnet.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = alexnet(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # Print loss (or any other metric) as needed\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yGbIMdp_GcM",
        "outputId": "79c88b6f-5da0-42bf-aafd-6a15058599c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.1591\n",
            "Epoch [1/10], Loss: 0.9198\n",
            "Epoch [1/10], Loss: 3.7292\n",
            "Epoch [1/10], Loss: 6.1978\n",
            "Epoch [1/10], Loss: 0.9069\n",
            "Epoch [1/10], Loss: 1.2353\n",
            "Epoch [1/10], Loss: 1.3394\n",
            "Epoch [1/10], Loss: 1.0054\n",
            "Epoch [1/10], Loss: 1.2669\n",
            "Epoch [1/10], Loss: 1.0365\n",
            "Epoch [1/10], Loss: 0.8264\n",
            "Epoch [1/10], Loss: 1.2103\n",
            "Epoch [1/10], Loss: 2.3859\n",
            "Epoch [1/10], Loss: 0.9945\n",
            "Epoch [1/10], Loss: 1.0468\n",
            "Epoch [2/10], Loss: 1.0524\n",
            "Epoch [2/10], Loss: 1.0471\n",
            "Epoch [2/10], Loss: 0.9936\n",
            "Epoch [2/10], Loss: 0.9376\n",
            "Epoch [2/10], Loss: 0.9644\n",
            "Epoch [2/10], Loss: 1.4728\n",
            "Epoch [2/10], Loss: 1.0550\n",
            "Epoch [2/10], Loss: 0.9455\n",
            "Epoch [2/10], Loss: 1.3890\n",
            "Epoch [2/10], Loss: 0.9231\n",
            "Epoch [2/10], Loss: 0.9544\n",
            "Epoch [2/10], Loss: 1.0799\n",
            "Epoch [2/10], Loss: 1.0567\n",
            "Epoch [2/10], Loss: 1.0465\n",
            "Epoch [2/10], Loss: 1.0483\n",
            "Epoch [3/10], Loss: 1.0614\n",
            "Epoch [3/10], Loss: 1.0194\n",
            "Epoch [3/10], Loss: 1.0776\n",
            "Epoch [3/10], Loss: 1.0383\n",
            "Epoch [3/10], Loss: 0.9913\n",
            "Epoch [3/10], Loss: 1.0390\n",
            "Epoch [3/10], Loss: 0.9799\n",
            "Epoch [3/10], Loss: 1.0603\n",
            "Epoch [3/10], Loss: 0.9645\n",
            "Epoch [3/10], Loss: 1.0586\n",
            "Epoch [3/10], Loss: 0.9265\n",
            "Epoch [3/10], Loss: 0.9210\n",
            "Epoch [3/10], Loss: 1.0154\n",
            "Epoch [3/10], Loss: 1.1460\n",
            "Epoch [3/10], Loss: 1.0680\n",
            "Epoch [4/10], Loss: 0.9363\n",
            "Epoch [4/10], Loss: 0.8329\n",
            "Epoch [4/10], Loss: 1.0031\n",
            "Epoch [4/10], Loss: 0.9563\n",
            "Epoch [4/10], Loss: 0.8886\n",
            "Epoch [4/10], Loss: 0.9039\n",
            "Epoch [4/10], Loss: 0.8167\n",
            "Epoch [4/10], Loss: 0.8964\n",
            "Epoch [4/10], Loss: 1.0411\n",
            "Epoch [4/10], Loss: 0.9899\n",
            "Epoch [4/10], Loss: 0.9347\n",
            "Epoch [4/10], Loss: 0.9254\n",
            "Epoch [4/10], Loss: 0.9049\n",
            "Epoch [4/10], Loss: 0.9762\n",
            "Epoch [4/10], Loss: 1.0162\n",
            "Epoch [5/10], Loss: 1.0733\n",
            "Epoch [5/10], Loss: 1.1039\n",
            "Epoch [5/10], Loss: 1.0916\n",
            "Epoch [5/10], Loss: 1.1613\n",
            "Epoch [5/10], Loss: 1.0761\n",
            "Epoch [5/10], Loss: 1.0852\n",
            "Epoch [5/10], Loss: 1.1435\n",
            "Epoch [5/10], Loss: 1.1179\n",
            "Epoch [5/10], Loss: 1.0952\n",
            "Epoch [5/10], Loss: 1.1072\n",
            "Epoch [5/10], Loss: 1.0505\n",
            "Epoch [5/10], Loss: 1.0719\n",
            "Epoch [5/10], Loss: 1.1001\n",
            "Epoch [5/10], Loss: 1.0727\n",
            "Epoch [5/10], Loss: 1.0413\n",
            "Epoch [6/10], Loss: 1.0596\n",
            "Epoch [6/10], Loss: 1.1729\n",
            "Epoch [6/10], Loss: 1.0483\n",
            "Epoch [6/10], Loss: 1.0520\n",
            "Epoch [6/10], Loss: 1.1033\n",
            "Epoch [6/10], Loss: 1.0924\n",
            "Epoch [6/10], Loss: 1.0936\n",
            "Epoch [6/10], Loss: 1.1036\n",
            "Epoch [6/10], Loss: 1.1044\n",
            "Epoch [6/10], Loss: 1.1027\n",
            "Epoch [6/10], Loss: 1.1057\n",
            "Epoch [6/10], Loss: 1.0924\n",
            "Epoch [6/10], Loss: 1.0909\n",
            "Epoch [6/10], Loss: 1.0966\n",
            "Epoch [6/10], Loss: 1.1189\n",
            "Epoch [7/10], Loss: 1.0906\n",
            "Epoch [7/10], Loss: 1.0915\n",
            "Epoch [7/10], Loss: 1.0999\n",
            "Epoch [7/10], Loss: 1.0993\n",
            "Epoch [7/10], Loss: 1.0933\n",
            "Epoch [7/10], Loss: 1.0980\n",
            "Epoch [7/10], Loss: 1.0940\n",
            "Epoch [7/10], Loss: 1.0933\n",
            "Epoch [7/10], Loss: 1.0940\n",
            "Epoch [7/10], Loss: 1.1029\n",
            "Epoch [7/10], Loss: 1.1002\n",
            "Epoch [7/10], Loss: 1.0913\n",
            "Epoch [7/10], Loss: 1.1006\n",
            "Epoch [7/10], Loss: 1.1024\n",
            "Epoch [7/10], Loss: 1.0863\n",
            "Epoch [8/10], Loss: 1.0809\n",
            "Epoch [8/10], Loss: 1.0039\n",
            "Epoch [8/10], Loss: 1.5691\n",
            "Epoch [8/10], Loss: 1.0667\n",
            "Epoch [8/10], Loss: 1.0002\n",
            "Epoch [8/10], Loss: 0.9684\n",
            "Epoch [8/10], Loss: 0.9101\n",
            "Epoch [8/10], Loss: 1.4492\n",
            "Epoch [8/10], Loss: 1.0995\n",
            "Epoch [8/10], Loss: 1.0962\n",
            "Epoch [8/10], Loss: 1.0980\n",
            "Epoch [8/10], Loss: 1.0970\n",
            "Epoch [8/10], Loss: 1.1080\n",
            "Epoch [8/10], Loss: 1.1059\n",
            "Epoch [8/10], Loss: 1.0953\n",
            "Epoch [9/10], Loss: 1.0974\n",
            "Epoch [9/10], Loss: 1.0995\n",
            "Epoch [9/10], Loss: 1.1063\n",
            "Epoch [9/10], Loss: 1.0983\n",
            "Epoch [9/10], Loss: 1.0993\n",
            "Epoch [9/10], Loss: 1.1017\n",
            "Epoch [9/10], Loss: 1.0994\n",
            "Epoch [9/10], Loss: 1.1092\n",
            "Epoch [9/10], Loss: 1.0930\n",
            "Epoch [9/10], Loss: 1.0969\n",
            "Epoch [9/10], Loss: 1.1059\n",
            "Epoch [9/10], Loss: 1.0903\n",
            "Epoch [9/10], Loss: 1.1011\n",
            "Epoch [9/10], Loss: 1.0980\n",
            "Epoch [9/10], Loss: 1.0972\n",
            "Epoch [10/10], Loss: 1.1008\n",
            "Epoch [10/10], Loss: 1.0970\n",
            "Epoch [10/10], Loss: 1.1028\n",
            "Epoch [10/10], Loss: 1.0985\n",
            "Epoch [10/10], Loss: 1.0905\n",
            "Epoch [10/10], Loss: 1.0940\n",
            "Epoch [10/10], Loss: 1.1008\n",
            "Epoch [10/10], Loss: 1.1070\n",
            "Epoch [10/10], Loss: 1.1036\n",
            "Epoch [10/10], Loss: 1.0928\n",
            "Epoch [10/10], Loss: 1.0998\n",
            "Epoch [10/10], Loss: 1.1018\n",
            "Epoch [10/10], Loss: 1.0990\n",
            "Epoch [10/10], Loss: 1.1023\n",
            "Epoch [10/10], Loss: 1.1008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "alexnet.eval()\n",
        "true_labels = []\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = alexnet(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        predictions.extend(predicted.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())"
      ],
      "metadata": {
        "id": "bK63pR_a_M36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics\n",
        "true_labels = np.array(true_labels)\n",
        "predictions = np.array(predictions)\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')"
      ],
      "metadata": {
        "id": "xeHVWGBoCftv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4631df5-5ee4-47df-ac8d-fbddcdc98c68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5pjRviKCmuq",
        "outputId": "99ccb71b-d1f6-4f18-bea4-8b2e27c1a0d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.23529411764705882\n",
            "Precision: 0.05536332179930795\n",
            "Recall: 0.23529411764705882\n",
            "F1 Score: 0.0896358543417367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Adding more fully connected layers for enhanced classifier"
      ],
      "metadata": {
        "id": "XneUSYzDFFcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "TMU2PV_oCrpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained AlexNet model\n",
        "alexnet = models.alexnet(pretrained=True)\n",
        "\n",
        "# Modify the model to use it as a feature extractor\n",
        "alexnet.classifier = nn.Sequential(*list(alexnet.classifier.children())[:-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlI7j8K8FY2k",
        "outputId": "36f6c9e4-3bfd-4595-94e6-f439082b8d45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define an enhanced custom classifier with additional fully connected layers\n",
        "class EnhancedClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EnhancedClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(4096, 1024)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(512, 256)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc4 = nn.Linear(256, 3)  # 3 classes: 'copy_moved', 'spliced', 'not_forged'\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "I6v4c5sGFdh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attach the enhanced classifier to AlexNet\n",
        "classifier = EnhancedClassifier()\n",
        "alexnet.classifier.add_module('enhanced_classifier', classifier)"
      ],
      "metadata": {
        "id": "aQKHmzmQFqO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations for dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "uPIrGrs8FyOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "dataset = ImageFolder(root='/content/drive/MyDrive/Datasets/Type_Det_Enhanced', transform=transform)\n",
        "\n",
        "# Split dataset into train and test set\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
      ],
      "metadata": {
        "id": "RMjHsd5tF41w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "SO9Ruz7_GBLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(alexnet.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "1lUTqnAUGIUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(alexnet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42iCMhXPGlUo",
        "outputId": "84ff55e6-1a9e-48e2-ef9d-4396b4bb7efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (enhanced_classifier): EnhancedClassifier(\n",
            "      (fc1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "      (relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
            "      (relu2): ReLU()\n",
            "      (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
            "      (relu3): ReLU()\n",
            "      (fc4): Linear(in_features=256, out_features=3, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    alexnet.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = alexnet(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # Print loss (or any other metric) as needed\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNC9Vkx4GLxZ",
        "outputId": "33e3fa8a-a99d-4d66-ac5c-a98a7a4de39b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.1020\n",
            "Epoch [1/10], Loss: 1.1126\n",
            "Epoch [1/10], Loss: 1.4509\n",
            "Epoch [1/10], Loss: 1.5479\n",
            "Epoch [1/10], Loss: 1.0930\n",
            "Epoch [1/10], Loss: 1.0973\n",
            "Epoch [1/10], Loss: 1.1237\n",
            "Epoch [1/10], Loss: 1.0835\n",
            "Epoch [1/10], Loss: 1.1798\n",
            "Epoch [1/10], Loss: 1.0890\n",
            "Epoch [1/10], Loss: 1.0934\n",
            "Epoch [1/10], Loss: 1.1114\n",
            "Epoch [1/10], Loss: 1.0984\n",
            "Epoch [1/10], Loss: 1.0967\n",
            "Epoch [1/10], Loss: 1.1011\n",
            "Epoch [1/10], Loss: 1.0979\n",
            "Epoch [1/10], Loss: 1.1065\n",
            "Epoch [1/10], Loss: 1.1004\n",
            "Epoch [1/10], Loss: 1.0940\n",
            "Epoch [1/10], Loss: 1.0814\n",
            "Epoch [1/10], Loss: 1.1123\n",
            "Epoch [1/10], Loss: 1.0675\n",
            "Epoch [1/10], Loss: 1.1512\n",
            "Epoch [1/10], Loss: 1.0879\n",
            "Epoch [1/10], Loss: 1.0998\n",
            "Epoch [1/10], Loss: 1.0973\n",
            "Epoch [1/10], Loss: 1.0983\n",
            "Epoch [1/10], Loss: 1.0999\n",
            "Epoch [1/10], Loss: 1.1002\n",
            "Epoch [1/10], Loss: 1.0980\n",
            "Epoch [1/10], Loss: 1.1054\n",
            "Epoch [1/10], Loss: 1.0943\n",
            "Epoch [1/10], Loss: 1.0924\n",
            "Epoch [1/10], Loss: 1.1087\n",
            "Epoch [1/10], Loss: 1.0981\n",
            "Epoch [1/10], Loss: 1.1093\n",
            "Epoch [1/10], Loss: 1.0908\n",
            "Epoch [1/10], Loss: 1.0920\n",
            "Epoch [2/10], Loss: 1.0952\n",
            "Epoch [2/10], Loss: 1.1235\n",
            "Epoch [2/10], Loss: 1.1089\n",
            "Epoch [2/10], Loss: 1.0983\n",
            "Epoch [2/10], Loss: 1.0943\n",
            "Epoch [2/10], Loss: 1.0980\n",
            "Epoch [2/10], Loss: 1.1212\n",
            "Epoch [2/10], Loss: 1.0990\n",
            "Epoch [2/10], Loss: 1.0775\n",
            "Epoch [2/10], Loss: 1.0993\n",
            "Epoch [2/10], Loss: 1.0932\n",
            "Epoch [2/10], Loss: 1.1010\n",
            "Epoch [2/10], Loss: 1.1130\n",
            "Epoch [2/10], Loss: 1.0989\n",
            "Epoch [2/10], Loss: 1.1022\n",
            "Epoch [2/10], Loss: 1.0964\n",
            "Epoch [2/10], Loss: 1.0921\n",
            "Epoch [2/10], Loss: 1.0996\n",
            "Epoch [2/10], Loss: 1.0988\n",
            "Epoch [2/10], Loss: 1.1012\n",
            "Epoch [2/10], Loss: 1.0878\n",
            "Epoch [2/10], Loss: 1.0866\n",
            "Epoch [2/10], Loss: 1.1001\n",
            "Epoch [2/10], Loss: 1.1040\n",
            "Epoch [2/10], Loss: 1.0792\n",
            "Epoch [2/10], Loss: 1.0886\n",
            "Epoch [2/10], Loss: 1.0919\n",
            "Epoch [2/10], Loss: 1.1182\n",
            "Epoch [2/10], Loss: 1.1385\n",
            "Epoch [2/10], Loss: 1.1335\n",
            "Epoch [2/10], Loss: 1.0888\n",
            "Epoch [2/10], Loss: 1.1466\n",
            "Epoch [2/10], Loss: 1.1010\n",
            "Epoch [2/10], Loss: 1.0959\n",
            "Epoch [2/10], Loss: 1.0948\n",
            "Epoch [2/10], Loss: 1.1041\n",
            "Epoch [2/10], Loss: 1.0965\n",
            "Epoch [2/10], Loss: 1.0992\n",
            "Epoch [3/10], Loss: 1.1258\n",
            "Epoch [3/10], Loss: 1.1085\n",
            "Epoch [3/10], Loss: 1.1015\n",
            "Epoch [3/10], Loss: 1.0927\n",
            "Epoch [3/10], Loss: 1.0875\n",
            "Epoch [3/10], Loss: 1.0656\n",
            "Epoch [3/10], Loss: 1.1015\n",
            "Epoch [3/10], Loss: 1.1005\n",
            "Epoch [3/10], Loss: 1.0935\n",
            "Epoch [3/10], Loss: 1.0955\n",
            "Epoch [3/10], Loss: 1.0940\n",
            "Epoch [3/10], Loss: 1.0976\n",
            "Epoch [3/10], Loss: 1.1023\n",
            "Epoch [3/10], Loss: 1.1061\n",
            "Epoch [3/10], Loss: 1.1002\n",
            "Epoch [3/10], Loss: 1.0993\n",
            "Epoch [3/10], Loss: 1.0986\n",
            "Epoch [3/10], Loss: 1.1008\n",
            "Epoch [3/10], Loss: 1.0946\n",
            "Epoch [3/10], Loss: 1.1051\n",
            "Epoch [3/10], Loss: 1.1059\n",
            "Epoch [3/10], Loss: 1.0869\n",
            "Epoch [3/10], Loss: 1.1010\n",
            "Epoch [3/10], Loss: 1.0757\n",
            "Epoch [3/10], Loss: 1.0863\n",
            "Epoch [3/10], Loss: 1.2042\n",
            "Epoch [3/10], Loss: 1.0986\n",
            "Epoch [3/10], Loss: 1.0843\n",
            "Epoch [3/10], Loss: 1.0849\n",
            "Epoch [3/10], Loss: 1.0888\n",
            "Epoch [3/10], Loss: 1.0260\n",
            "Epoch [3/10], Loss: 1.1322\n",
            "Epoch [3/10], Loss: 1.0585\n",
            "Epoch [3/10], Loss: 0.9612\n",
            "Epoch [3/10], Loss: 1.0438\n",
            "Epoch [3/10], Loss: 1.6789\n",
            "Epoch [3/10], Loss: 1.0955\n",
            "Epoch [3/10], Loss: 1.0978\n",
            "Epoch [4/10], Loss: 1.0985\n",
            "Epoch [4/10], Loss: 1.0985\n",
            "Epoch [4/10], Loss: 1.1008\n",
            "Epoch [4/10], Loss: 1.0982\n",
            "Epoch [4/10], Loss: 1.0971\n",
            "Epoch [4/10], Loss: 1.1012\n",
            "Epoch [4/10], Loss: 1.0940\n",
            "Epoch [4/10], Loss: 1.0940\n",
            "Epoch [4/10], Loss: 1.0992\n",
            "Epoch [4/10], Loss: 1.1004\n",
            "Epoch [4/10], Loss: 1.0990\n",
            "Epoch [4/10], Loss: 1.0978\n",
            "Epoch [4/10], Loss: 1.0990\n",
            "Epoch [4/10], Loss: 1.1046\n",
            "Epoch [4/10], Loss: 1.1022\n",
            "Epoch [4/10], Loss: 1.0969\n",
            "Epoch [4/10], Loss: 1.0952\n",
            "Epoch [4/10], Loss: 1.1092\n",
            "Epoch [4/10], Loss: 1.0972\n",
            "Epoch [4/10], Loss: 1.1027\n",
            "Epoch [4/10], Loss: 1.0917\n",
            "Epoch [4/10], Loss: 1.1023\n",
            "Epoch [4/10], Loss: 1.0999\n",
            "Epoch [4/10], Loss: 1.0947\n",
            "Epoch [4/10], Loss: 1.0976\n",
            "Epoch [4/10], Loss: 1.0982\n",
            "Epoch [4/10], Loss: 1.0985\n",
            "Epoch [4/10], Loss: 1.0948\n",
            "Epoch [4/10], Loss: 1.1010\n",
            "Epoch [4/10], Loss: 1.0959\n",
            "Epoch [4/10], Loss: 1.1014\n",
            "Epoch [4/10], Loss: 1.0920\n",
            "Epoch [4/10], Loss: 1.0992\n",
            "Epoch [4/10], Loss: 1.0992\n",
            "Epoch [4/10], Loss: 1.0967\n",
            "Epoch [4/10], Loss: 1.0934\n",
            "Epoch [4/10], Loss: 1.0993\n",
            "Epoch [4/10], Loss: 1.1066\n",
            "Epoch [5/10], Loss: 1.0994\n",
            "Epoch [5/10], Loss: 1.1003\n",
            "Epoch [5/10], Loss: 1.0908\n",
            "Epoch [5/10], Loss: 1.0988\n",
            "Epoch [5/10], Loss: 1.0928\n",
            "Epoch [5/10], Loss: 1.0930\n",
            "Epoch [5/10], Loss: 1.1054\n",
            "Epoch [5/10], Loss: 1.0933\n",
            "Epoch [5/10], Loss: 1.0973\n",
            "Epoch [5/10], Loss: 1.1019\n",
            "Epoch [5/10], Loss: 1.1036\n",
            "Epoch [5/10], Loss: 1.0870\n",
            "Epoch [5/10], Loss: 1.0976\n",
            "Epoch [5/10], Loss: 1.0985\n",
            "Epoch [5/10], Loss: 1.1017\n",
            "Epoch [5/10], Loss: 1.0965\n",
            "Epoch [5/10], Loss: 1.0964\n",
            "Epoch [5/10], Loss: 1.1087\n",
            "Epoch [5/10], Loss: 1.1044\n",
            "Epoch [5/10], Loss: 1.0895\n",
            "Epoch [5/10], Loss: 1.0895\n",
            "Epoch [5/10], Loss: 1.1052\n",
            "Epoch [5/10], Loss: 1.0864\n",
            "Epoch [5/10], Loss: 1.1053\n",
            "Epoch [5/10], Loss: 1.0937\n",
            "Epoch [5/10], Loss: 1.1030\n",
            "Epoch [5/10], Loss: 1.1008\n",
            "Epoch [5/10], Loss: 1.1071\n",
            "Epoch [5/10], Loss: 1.1111\n",
            "Epoch [5/10], Loss: 1.0937\n",
            "Epoch [5/10], Loss: 1.0920\n",
            "Epoch [5/10], Loss: 1.0953\n",
            "Epoch [5/10], Loss: 1.0991\n",
            "Epoch [5/10], Loss: 1.1034\n",
            "Epoch [5/10], Loss: 1.1142\n",
            "Epoch [5/10], Loss: 1.0936\n",
            "Epoch [5/10], Loss: 1.0978\n",
            "Epoch [5/10], Loss: 1.1015\n",
            "Epoch [6/10], Loss: 1.0949\n",
            "Epoch [6/10], Loss: 1.1079\n",
            "Epoch [6/10], Loss: 1.1000\n",
            "Epoch [6/10], Loss: 1.0975\n",
            "Epoch [6/10], Loss: 1.0994\n",
            "Epoch [6/10], Loss: 1.1048\n",
            "Epoch [6/10], Loss: 1.0973\n",
            "Epoch [6/10], Loss: 1.0947\n",
            "Epoch [6/10], Loss: 1.1003\n",
            "Epoch [6/10], Loss: 1.0982\n",
            "Epoch [6/10], Loss: 1.0999\n",
            "Epoch [6/10], Loss: 1.1006\n",
            "Epoch [6/10], Loss: 1.0991\n",
            "Epoch [6/10], Loss: 1.1009\n",
            "Epoch [6/10], Loss: 1.1003\n",
            "Epoch [6/10], Loss: 1.0980\n",
            "Epoch [6/10], Loss: 1.0996\n",
            "Epoch [6/10], Loss: 1.0979\n",
            "Epoch [6/10], Loss: 1.0975\n",
            "Epoch [6/10], Loss: 1.0996\n",
            "Epoch [6/10], Loss: 1.0997\n",
            "Epoch [6/10], Loss: 1.0983\n",
            "Epoch [6/10], Loss: 1.0987\n",
            "Epoch [6/10], Loss: 1.0998\n",
            "Epoch [6/10], Loss: 1.0993\n",
            "Epoch [6/10], Loss: 1.0980\n",
            "Epoch [6/10], Loss: 1.0976\n",
            "Epoch [6/10], Loss: 1.0989\n",
            "Epoch [6/10], Loss: 1.0988\n",
            "Epoch [6/10], Loss: 1.0985\n",
            "Epoch [6/10], Loss: 1.0984\n",
            "Epoch [6/10], Loss: 1.0969\n",
            "Epoch [6/10], Loss: 1.0976\n",
            "Epoch [6/10], Loss: 1.0964\n",
            "Epoch [6/10], Loss: 1.0974\n",
            "Epoch [6/10], Loss: 1.0983\n",
            "Epoch [6/10], Loss: 1.0950\n",
            "Epoch [6/10], Loss: 1.1017\n",
            "Epoch [7/10], Loss: 1.0991\n",
            "Epoch [7/10], Loss: 1.0970\n",
            "Epoch [7/10], Loss: 1.1059\n",
            "Epoch [7/10], Loss: 1.0980\n",
            "Epoch [7/10], Loss: 1.1015\n",
            "Epoch [7/10], Loss: 1.0993\n",
            "Epoch [7/10], Loss: 1.0993\n",
            "Epoch [7/10], Loss: 1.0926\n",
            "Epoch [7/10], Loss: 1.1061\n",
            "Epoch [7/10], Loss: 1.0980\n",
            "Epoch [7/10], Loss: 1.0961\n",
            "Epoch [7/10], Loss: 1.0961\n",
            "Epoch [7/10], Loss: 1.0987\n",
            "Epoch [7/10], Loss: 1.0957\n",
            "Epoch [7/10], Loss: 1.1038\n",
            "Epoch [7/10], Loss: 1.1033\n",
            "Epoch [7/10], Loss: 1.0928\n",
            "Epoch [7/10], Loss: 1.0990\n",
            "Epoch [7/10], Loss: 1.0972\n",
            "Epoch [7/10], Loss: 1.0917\n",
            "Epoch [7/10], Loss: 1.1002\n",
            "Epoch [7/10], Loss: 1.0981\n",
            "Epoch [7/10], Loss: 1.0955\n",
            "Epoch [7/10], Loss: 1.0979\n",
            "Epoch [7/10], Loss: 1.0955\n",
            "Epoch [7/10], Loss: 1.0993\n",
            "Epoch [7/10], Loss: 1.0998\n",
            "Epoch [7/10], Loss: 1.0996\n",
            "Epoch [7/10], Loss: 1.0949\n",
            "Epoch [7/10], Loss: 1.0932\n",
            "Epoch [7/10], Loss: 1.1044\n",
            "Epoch [7/10], Loss: 1.0977\n",
            "Epoch [7/10], Loss: 1.0928\n",
            "Epoch [7/10], Loss: 1.1033\n",
            "Epoch [7/10], Loss: 1.1072\n",
            "Epoch [7/10], Loss: 1.0957\n",
            "Epoch [7/10], Loss: 1.0943\n",
            "Epoch [7/10], Loss: 1.0984\n",
            "Epoch [8/10], Loss: 1.1093\n",
            "Epoch [8/10], Loss: 1.0998\n",
            "Epoch [8/10], Loss: 1.1028\n",
            "Epoch [8/10], Loss: 1.1026\n",
            "Epoch [8/10], Loss: 1.1027\n",
            "Epoch [8/10], Loss: 1.0968\n",
            "Epoch [8/10], Loss: 1.0935\n",
            "Epoch [8/10], Loss: 1.0920\n",
            "Epoch [8/10], Loss: 1.1012\n",
            "Epoch [8/10], Loss: 1.1018\n",
            "Epoch [8/10], Loss: 1.1002\n",
            "Epoch [8/10], Loss: 1.0987\n",
            "Epoch [8/10], Loss: 1.0951\n",
            "Epoch [8/10], Loss: 1.1020\n",
            "Epoch [8/10], Loss: 1.0979\n",
            "Epoch [8/10], Loss: 1.0968\n",
            "Epoch [8/10], Loss: 1.1000\n",
            "Epoch [8/10], Loss: 1.0960\n",
            "Epoch [8/10], Loss: 1.0975\n",
            "Epoch [8/10], Loss: 1.1004\n",
            "Epoch [8/10], Loss: 1.0937\n",
            "Epoch [8/10], Loss: 1.0983\n",
            "Epoch [8/10], Loss: 1.0924\n",
            "Epoch [8/10], Loss: 1.0918\n",
            "Epoch [8/10], Loss: 1.1013\n",
            "Epoch [8/10], Loss: 1.0965\n",
            "Epoch [8/10], Loss: 1.0961\n",
            "Epoch [8/10], Loss: 1.0949\n",
            "Epoch [8/10], Loss: 1.0944\n",
            "Epoch [8/10], Loss: 1.0905\n",
            "Epoch [8/10], Loss: 1.1012\n",
            "Epoch [8/10], Loss: 1.1062\n",
            "Epoch [8/10], Loss: 1.1139\n",
            "Epoch [8/10], Loss: 1.0996\n",
            "Epoch [8/10], Loss: 1.1018\n",
            "Epoch [8/10], Loss: 1.0899\n",
            "Epoch [8/10], Loss: 1.0878\n",
            "Epoch [8/10], Loss: 1.1164\n",
            "Epoch [9/10], Loss: 1.1078\n",
            "Epoch [9/10], Loss: 1.0939\n",
            "Epoch [9/10], Loss: 1.0918\n",
            "Epoch [9/10], Loss: 1.0899\n",
            "Epoch [9/10], Loss: 1.0996\n",
            "Epoch [9/10], Loss: 1.1047\n",
            "Epoch [9/10], Loss: 1.0886\n",
            "Epoch [9/10], Loss: 1.1013\n",
            "Epoch [9/10], Loss: 1.0964\n",
            "Epoch [9/10], Loss: 1.0859\n",
            "Epoch [9/10], Loss: 1.0960\n",
            "Epoch [9/10], Loss: 1.0977\n",
            "Epoch [9/10], Loss: 1.1069\n",
            "Epoch [9/10], Loss: 1.0897\n",
            "Epoch [9/10], Loss: 1.0990\n",
            "Epoch [9/10], Loss: 1.0995\n",
            "Epoch [9/10], Loss: 1.0946\n",
            "Epoch [9/10], Loss: 1.0904\n",
            "Epoch [9/10], Loss: 1.0963\n",
            "Epoch [9/10], Loss: 1.0926\n",
            "Epoch [9/10], Loss: 1.1056\n",
            "Epoch [9/10], Loss: 1.0942\n",
            "Epoch [9/10], Loss: 1.0972\n",
            "Epoch [9/10], Loss: 1.0942\n",
            "Epoch [9/10], Loss: 1.1097\n",
            "Epoch [9/10], Loss: 1.1025\n",
            "Epoch [9/10], Loss: 1.1061\n",
            "Epoch [9/10], Loss: 1.0938\n",
            "Epoch [9/10], Loss: 1.1021\n",
            "Epoch [9/10], Loss: 1.0977\n",
            "Epoch [9/10], Loss: 1.0972\n",
            "Epoch [9/10], Loss: 1.1152\n",
            "Epoch [9/10], Loss: 1.0981\n",
            "Epoch [9/10], Loss: 1.1059\n",
            "Epoch [9/10], Loss: 1.1154\n",
            "Epoch [9/10], Loss: 1.1035\n",
            "Epoch [9/10], Loss: 1.0916\n",
            "Epoch [9/10], Loss: 1.0946\n",
            "Epoch [10/10], Loss: 1.0962\n",
            "Epoch [10/10], Loss: 1.0933\n",
            "Epoch [10/10], Loss: 1.0981\n",
            "Epoch [10/10], Loss: 1.1026\n",
            "Epoch [10/10], Loss: 1.0949\n",
            "Epoch [10/10], Loss: 1.0975\n",
            "Epoch [10/10], Loss: 1.1004\n",
            "Epoch [10/10], Loss: 1.0961\n",
            "Epoch [10/10], Loss: 1.0991\n",
            "Epoch [10/10], Loss: 1.0998\n",
            "Epoch [10/10], Loss: 1.0981\n",
            "Epoch [10/10], Loss: 1.0965\n",
            "Epoch [10/10], Loss: 1.0936\n",
            "Epoch [10/10], Loss: 1.0958\n",
            "Epoch [10/10], Loss: 1.0945\n",
            "Epoch [10/10], Loss: 1.0992\n",
            "Epoch [10/10], Loss: 1.0995\n",
            "Epoch [10/10], Loss: 1.0923\n",
            "Epoch [10/10], Loss: 1.0961\n",
            "Epoch [10/10], Loss: 1.0939\n",
            "Epoch [10/10], Loss: 1.0999\n",
            "Epoch [10/10], Loss: 1.1018\n",
            "Epoch [10/10], Loss: 1.1042\n",
            "Epoch [10/10], Loss: 1.1059\n",
            "Epoch [10/10], Loss: 1.0944\n",
            "Epoch [10/10], Loss: 1.0972\n",
            "Epoch [10/10], Loss: 1.0978\n",
            "Epoch [10/10], Loss: 1.0984\n",
            "Epoch [10/10], Loss: 1.0951\n",
            "Epoch [10/10], Loss: 1.0925\n",
            "Epoch [10/10], Loss: 1.0984\n",
            "Epoch [10/10], Loss: 1.1041\n",
            "Epoch [10/10], Loss: 1.1015\n",
            "Epoch [10/10], Loss: 1.1048\n",
            "Epoch [10/10], Loss: 1.0945\n",
            "Epoch [10/10], Loss: 1.0971\n",
            "Epoch [10/10], Loss: 1.1067\n",
            "Epoch [10/10], Loss: 1.1055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "alexnet.eval()\n",
        "true_labels = []\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = alexnet(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        predictions.extend(predicted.cpu().numpy())\n",
        "        true_labels.extend(labels.cpu().numpy())"
      ],
      "metadata": {
        "id": "s2WsJ81RGv8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics\n",
        "true_labels = np.array(true_labels)\n",
        "predictions = np.array(predictions)\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "precision, recall, f1_score, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')"
      ],
      "metadata": {
        "id": "8kpudnJ0HB_H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4664b89-f2d5-4ffe-df85-f704362d0741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLy5dI7YHFxR",
        "outputId": "5215efb8-c87d-4e07-8b4a-bc057e379028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.32673267326732675\n",
            "Precision: 0.10675423978041369\n",
            "Recall: 0.32673267326732675\n",
            "F1 Score: 0.16092803310181764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3IobDtmsJpcW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}